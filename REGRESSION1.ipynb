{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though both of them are regression algorithms themselves, simple regression take only one input feature into it's model, like taking age as an input for calculating the height of a person.\n",
    "Whereas in multiple regression, multiple input features can be provided into the model for calculating the best fit line. For example in the house price dataset, the price of the house in dependent upon the carpet area, number of rooms, number of bathrooms etc. features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linearity: relationship between the independent and dependent features in the dataset should must be linear. This can be checked by observing the changes in the response variable is proportional to the change in predictor variable or not.\n",
    "- The residuals should be in normal distribution, means that the residuals should form a bell-shaped curve when plotted.\n",
    "- Outliers can influence the regression line and model. Too much presence of outliers in the dataset results in an imperfect regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intercept: Represents the value of dependent variable Y when the independent variable X is equal to zero.\n",
    "- Slope: Represents the change in the dependent variable Y for one unit change in the independent variable X. It indicates the rate of change in Y concerning the unit change in X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the house price prediction:\n",
    "- If the intercept is Rs.45000, it implies that for a zero squarefoot house, the price would be Rs.45000(practically impossible)\n",
    "- If the slope coefficient is Rs.5000 per square foot, this means on average for each additional square foot, the house price increases by Rs.5000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is an iterative optimization algorithm used to find the minimum of a function. objective of it is to minimize a cost function by iteratively changing the model parameters, by calculating the partial derivatives of the cost function based on the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent is used for linear regression, logistic regression and many parts in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regression is an extetion of simple linear regression that involves predicting a dependent variable using multiple independent variables. In this model, multiple features can be taken as input for model predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between simple and multiple linear regression is that simple linear regression takes only one input feature, while multiple regression is capable of taking n numbers of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity refers to a situation in multiple linear regression where two or more predictor variables are highly correlated with each other. This high correlation may cause issues in the regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effects on Multicollinearity:\n",
    "- it becomes challenging to precisely estimate the impact of each individual predictor variable on the dependent variable if multicollinearity is present.\n",
    "\n",
    "Detecting Multicollinearity:\n",
    "- By computing the correlation coefficients among predictor variables, finding high correlation refers to potential multicollinearity issues.\n",
    "\n",
    "Addressing Multicollinearity:\n",
    "- Consider removing on of the highly correlated values from the model if they convey similar informations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression is a type of regression analysis which is used when the relationship between the independent and dependent variable is curvilinear rather than linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference from linear regression are:\n",
    "- relationship is modeled as higher degree polynomial\n",
    "- polynomial regression can fir curves that bettwe capture complex patterns in the data rather than straight lines fitted in the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- can model complex nonlinear relationships between variables compared to linear regression, allwoing it to fit curves to capture patterns that a linear model might not cauptre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disadvantages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As the degree of polynomial increases, the model becomes more complex, higher order ploynomials may lead to overfitting, where model fails to generalize data well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suitable Usecase for Polynomial Relationship:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When the relationship between dependent and independent variables is clearly non-linear and cannot be represented in a straight line, polynomial regression is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
